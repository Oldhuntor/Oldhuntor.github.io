<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Posts | Xuanhao&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - Xuanhao&#39;s Blog">
<meta name="author" content="">
<link rel="canonical" href="https://oldhuntor.github.io/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://oldhuntor.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://oldhuntor.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://oldhuntor.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://oldhuntor.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://oldhuntor.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://oldhuntor.github.io/posts/index.xml">
<link rel="alternate" hreflang="en" href="https://oldhuntor.github.io/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://oldhuntor.github.io/posts/">
  <meta property="og:site_name" content="Xuanhao&#39;s Blog">
  <meta property="og:title" content="Posts">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Posts">
<meta name="twitter:description" content="">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://oldhuntor.github.io/posts/"
    }
  ]
}
</script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.13/katex.min.css">
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.13/katex.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.13/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body);"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
          ]
        });
      });
    </script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://oldhuntor.github.io/" accesskey="h" title="Xuanhao&#39;s Blog (Alt + H)">Xuanhao&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://oldhuntor.github.io/posts/about-me" title="About Me">
                    <span>About Me</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Journey to a universal hedge system (part 2)
    </h2>
  </header>
  <div class="entry-content">
    <p>Journey to a universal hedge system (part 2) In the previous post we have talked about the implementation of models in pairs trading and their experiment, now let’s try these strategies out using a backtesting framework.
Model budget analysis Notice that the BSTS model has o(n) computation complexity. Other models have negligible complexity level.
Backtesting framework The backtesting frame uses simple object-oriented programming structure. Strategy flow chart The strategy can multiple exit position options to prevent high drop down. ...</p>
  </div>
  <footer class="entry-footer"><span title='2025-02-09 19:12:16 +0100 CET'>February 9, 2025</span>&nbsp;·&nbsp;3 min</footer>
  <a class="entry-link" aria-label="post link to Journey to a universal hedge system (part 2)" href="https://oldhuntor.github.io/posts/story-of-arbitrage2/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Journey to a universal hedge system (part I)
    </h2>
  </header>
  <div class="entry-content">
    <p>Journey to a universal hedge system Intro Statistical arbitrage or hedging has already been known for a long time, people usually tackle this trading strategy with models that have strong assumptions, and generally have only limited amount of asset pairs to trade based on the some macro or micro economics assumption.
In this essay, we want to explore more modern and diverse statistical method or machine learning methods for hedging. We will address two questions:
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-02-08 19:12:16 +0100 CET'>February 8, 2025</span>&nbsp;·&nbsp;9 min</footer>
  <a class="entry-link" aria-label="post link to Journey to a universal hedge system (part I)" href="https://oldhuntor.github.io/posts/story-of-arbitrage1/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Bayesian Cointegration codes
    </h2>
  </header>
  <div class="entry-content">
    <p>Cointegration strategy backtesting framework from backtest_multi_symbols import Broker, BarData, Backtestor, Position, DailyBar from collections import deque from statsmodels.tsa.stattools import coint import pandas as pd import numpy as np from itertools import combinations from sklearn.linear_model import LinearRegression from statsmodels.tsa.stattools import adfuller from model_new.bayesian_regression import bayesian_rolling_window from model_new.jointCov2 import fit_HGP from model_new.BayesGAM import bayesian_gam_with_splines from model_new.BSTS import bsts_fit class Log: def __init__(self, broker: Broker): self.resultPath = &#39;backTestResult/backtestLog&#39; self.logs = [] self.broker = broker def logging(self, bars: dict): data = {} for symbol in bars: data[f&#34;close_{symbol}&#34;] = bars[symbol].close pos = self.broker.positions.get(symbol, 0) if pos != 0: data[f&#34;position_{symbol}&#34;] = self.broker.positions[symbol].volume data[f&#34;position_{symbol}_worth&#34;] = self.broker.positions[symbol].volume * bars[symbol].close data[&#39;time&#39;] = bars[symbol].time equity = self.broker.calculate_total_account_equity(bars) data[&#34;equity&#34;] = equity data[&#39;cash&#39;] = self.broker.cash self.logs.append(data) def save_logs(self): df = pd.DataFrame(self.logs) # df.to_csv(self.resultPath &#43; &#39;.csv&#39;, index=False) class BacktestorPairTrading(Backtestor): def __init__(self, broker: Broker, strategy, log, start, end): super().__init__(broker, strategy, log, start, end) self.log: Log = log def run_backtest(self): for i in range(self.data_length): bars = {} for symbol in self.symbols: data = self.data[f&#39;{symbol}&#39;].iloc[i] bar = BarData(data[&#39;timestamp&#39;], data[&#39;open&#39;], data[&#39;high&#39;], data[&#39;low&#39;], ((data[&#39;close&#39;])), data[&#39;volume&#39;]) bars[symbol] = bar self.strategy.processBar(bars) self.log.logging(bars) equity = self.broker.calculate_total_account_equity(bars) accountPNL = equity - self.strategy.initial_balance if accountPNL/self.strategy.initial_balance &lt; -self.strategy.stop_loss: print(f&#34;stop loss at {self.strategy.stop_loss} !!!&#34;) break self.on_close(bars) self.log.save_logs() def on_close(self, bars): if self.strategy.is_open: print(&#39;out of time force close&#39;) self.strategy.close_position_new(bars, ignore_diff=True) class Cointegration: def __init__(self, broker: Broker, setting: dict): self.short_leg = setting[&#39;short_leg&#39;] self.long_leg = setting[&#39;long_leg&#39;] self.open_margin = setting[&#39;open_margin&#39;] self.close_margin = setting[&#39;close_margin&#39;] self.grid_amount = setting[&#39;grid_amount&#39;] self.array_len = setting[&#39;array_len&#39;] self.stop_loss = setting[&#39;stop_loss&#39;] self.pValue = setting[&#39;pValue&#39;] self.initial_balance = broker.cash self.maximum_holding_period = setting[&#39;maximum_holding_period&#39;] self.broker = broker self.beta = None self.intercept = None self.mean = None self.dev = None self.start = False self.open_diff = None self.bar_array = deque(maxlen=self.array_len) self.spread_array = deque(maxlen=self.array_len) self.is_open = False self.holding_count = 0 def get_model(self): pass def get_legs(self): long_legs = [] short_legs = [] for i in range(self.array_len): bar = self.bar_array[i] long_legs.append(np.log(bar[self.long_leg])) short_legs.append(np.log(bar[self.short_leg])) return long_legs, short_legs def get_beta(self): long_legs, short_legs = self.get_legs() # 使用 scikit-learn 回归模型计算 Beta（不带截距） long_legs = np.array(long_legs).reshape(-1, 1) short_legs = np.array(short_legs) model = LinearRegression(fit_intercept=True).fit(long_legs, short_legs) beta = model.coef_[0] intercept = model.intercept_ return beta, intercept def get_beta_BayesRegression(self): long_legs, short_legs = self.get_legs() result = bayesian_rolling_window(long_legs, short_legs, window_size=20) y_values = result[&#39;y&#39;] beta_values = result[&#39;beta&#39;] mu_values = result[&#39;mu&#39;] epsilon_values = result[&#39;epsilon&#39;] y_pred_mean = y_values[&#39;mean&#39;] y_pred_upper = y_values[&#39;upper&#39;] y_pred_lower = y_values[&#39;lower&#39;] beta_posterior = beta_values[&#39;mean&#39;] beta_upper = beta_values[&#39;upper&#39;] beta_lower = beta_values[&#39;lower&#39;] mu_posterior = mu_values[&#39;mean&#39;] mu_upper = mu_values[&#39;upper&#39;] mu_lower = mu_values[&#39;lower&#39;] epsilon_mean = epsilon_values[&#39;mean&#39;] epsilon_upper = epsilon_values[&#39;upper&#39;] epsilon_lower = epsilon_values[&#39;lower&#39;] return beta_posterior[-1], mu_posterior[-1] def get_beta_GPs(self): long_legs, short_legs = self.get_legs() long_legs = np.array(long_legs) short_legs = np.array(short_legs) result = fit_HGP(long_legs, short_legs) y_values = result[&#39;y&#39;] beta_values = result[&#39;beta&#39;] mu_values = result[&#39;mu&#39;] epsilon_values = result[&#39;epsilon&#39;] y_pred_mean = y_values[&#39;mean&#39;] y_pred_upper = y_values[&#39;upper&#39;] y_pred_lower = y_values[&#39;lower&#39;] beta_posterior = beta_values[&#39;mean&#39;] beta_upper = beta_values[&#39;upper&#39;] beta_lower = beta_values[&#39;lower&#39;] mu_posterior = mu_values[&#39;mean&#39;] mu_upper = mu_values[&#39;upper&#39;] mu_lower = mu_values[&#39;lower&#39;] epsilon_mean = epsilon_values[&#39;mean&#39;] epsilon_upper = epsilon_values[&#39;upper&#39;] epsilon_lower = epsilon_values[&#39;lower&#39;] return np.float64(beta_posterior[-1]), np.float64(mu_posterior[-1]) def get_beta_BSTS(self): pass def get_beta_GAM(self): long_legs = [] short_legs = [] for i in range(self.array_len): bar = self.bar_array[i] long_legs.append(bar[self.long_leg]) short_legs.append(bar[self.short_leg]) long_legs = np.array(long_legs) short_legs = np.array(short_legs) result = bayesian_gam_with_splines(long_legs,short_legs,df=10) y_values = result[&#39;y&#39;] beta_values = result[&#39;beta&#39;] mu_values = result[&#39;mu&#39;] epsilon_values = result[&#39;epsilon&#39;] y_pred_mean = y_values[&#39;mean&#39;] y_pred_upper = y_values[&#39;upper&#39;] y_pred_lower = y_values[&#39;lower&#39;] beta_posterior = beta_values[&#39;mean&#39;] beta_upper = beta_values[&#39;upper&#39;] beta_lower = beta_values[&#39;lower&#39;] mu_posterior = mu_values[&#39;mean&#39;] mu_upper = mu_values[&#39;upper&#39;] mu_lower = mu_values[&#39;lower&#39;] epsilon_mean = epsilon_values[&#39;mean&#39;] epsilon_upper = epsilon_values[&#39;upper&#39;] epsilon_lower = epsilon_values[&#39;lower&#39;] return beta_posterior[-1], mu_posterior[-1] def processBar(self, bars: dict): from math import log # append log data bar = { self.short_leg: (bars[self.short_leg].close), self.long_leg: (bars[self.long_leg].close), } self.bar_array.append(bar) if len(self.bar_array) &lt; self.array_len: return p_value = self.coin_test() spread, _ = self.spread(bars) self.spread_array.append(spread) if len(self.spread_array) &lt; self.array_len/5: return if self.is_open: self.holding_count &#43;= 1 spread, _ = self.spread(bars) diff = (spread - self.mean) / self.dev if self.holding_count &gt;= self.maximum_holding_period: print(&#39;holding too long force quit&#39;) self.close_position_new(bars, ignore_diff=True) self.holding_count = 0 return if self.mean: diff = (spread - self.mean) / self.dev # print(f&#34;current diff {diff}&#34;) adf_center = adfuller(self.spread_array, regression=&#39;c&#39;)[1] adf_trend = adfuller(self.spread_array, regression=&#39;ct&#39;)[1] if adf_center &lt; self.pValue: self.is_stationary = True else: self.is_stationary = False # if adf_trend &lt; 0.05: # print(f&#39;adf ct test result {adf_trend}, has a trend, not enter trading&#39;) # return # if p_value &lt;= self.pValue: if self.is_stationary: self.hedge(bars) elif self.is_open: self.close_position_new(bars) def hedge(self, bars: dict): if not self.is_open: # self.open_position(bars) self.open_position_new(bars) else: self.close_position_new(bars) def open_position_new(self, bars: dict): spread, _ = self.spread(bars) self.mean, self.dev = self.get_diff(spread) diff = (spread - self.mean) / self.dev long_leg_price = (bars[self.long_leg].close) short_leg_price = (bars[self.short_leg].close) time = bars[self.short_leg].time short_leg_qty = self.grid_amount/(long_leg_price*abs(self.beta) &#43; short_leg_price) long_leg_qty = short_leg_qty*abs(self.beta) if abs(diff) &gt; 2: print( f&#39;open parameter beta: {self.beta}, intercept: {self.intercept}, spread mean:{self.mean}, spread dev {self.dev}, diff:{diff} , time:{time}&#39;) self.open_diff = diff if self.beta &lt; 0: if diff &gt; 0: self.broker.short( price=long_leg_price, symbol=self.long_leg, vol=long_leg_qty, leverage=1, time=time) self.broker.short( price=short_leg_price, symbol=self.short_leg, vol=short_leg_qty, leverage=1, time=time) self.is_open = True else: self.broker.long( price=long_leg_price, symbol=self.long_leg, vol=long_leg_qty, leverage=1, time=time) self.broker.long( price=short_leg_price, symbol=self.short_leg, vol=short_leg_qty, leverage=1, time=time) self.is_open = True else: if diff &gt; 0: self.broker.long( price=long_leg_price, symbol=self.long_leg, vol=long_leg_qty, leverage=1, time=time) self.broker.short( price=short_leg_price, symbol=self.short_leg, vol=short_leg_qty, leverage=1, time=time) self.is_open = True else: self.broker.long( price=short_leg_price, symbol=self.short_leg, vol=short_leg_qty, leverage=1, time=time) self.broker.short( price=long_leg_price, symbol=self.long_leg, vol=long_leg_qty, leverage=1, time=time) self.is_open = True def close_position_new(self, bars: dict, ignore_diff=False): spread, _ = self.spread(bars) diff = (spread - self.mean) / self.dev # calculate position pnl long_leg_price = (bars[self.long_leg].close) short_leg_price = (bars[self.short_leg].close) time = bars[self.short_leg].time long_leg_pos: Position = self.broker.positions[self.long_leg] short_leg_pos: Position = self.broker.positions[self.short_leg] # Close the position when the unrealize loss is too much !!! # profit_rate = self.broker.get_current_pos_profit_rate(bars) # if profit_rate &lt; -0.1: # print(&#39;position profit rate is too low, force quit&#39;) # ignore_diff = True if (self.open_diff &gt; 0 and diff &lt; 0) or (self.open_diff &lt; 0 and diff &gt; 0) or ignore_diff: # if abs(diff) &lt; -2 or ignore_diff: self.holding_count = 0 print( f&#39;close parameter beta: {self.beta}, intercept: {self.intercept}, spread mean:{self.mean}, spread dev {self.dev}, diff:{diff} , time:{time}&#39;) if short_leg_pos.direction == &#39;short&#39;: self.broker.cover_short( price=short_leg_price, symbol=self.short_leg, vol=short_leg_pos.volume, time=time) else: self.broker.cover_long( price=short_leg_price, symbol=self.short_leg, vol=short_leg_pos.volume, time=time) if long_leg_pos.direction == &#39;short&#39;: self.broker.cover_short( price=long_leg_price, symbol=self.long_leg, vol=long_leg_pos.volume, time=time) else: self.broker.cover_long( price=long_leg_price, symbol=self.long_leg, vol=long_leg_pos.volume, time=time) self.is_open = False self.beta, self.intercept = None, None def spread(self, bars: dict): long: BarData = bars[self.long_leg] short: BarData = bars[self.short_leg] long_price = (long.close) short_price = (short.close) spread = short_price - (self.beta * long_price &#43; self.intercept) diff = spread / (self.beta * long_price &#43; self.intercept) return spread, diff def get_diff(self, spread): mean = np.mean(self.spread_array) dev = np.std(self.spread_array) return mean, dev def coin_test(self): long_legs = [] short_legs = [] for i in range(self.array_len): bar = self.bar_array[i] long_legs.append(bar[self.long_leg]) short_legs.append(bar[self.short_leg]) if not self.beta: self.beta, self.intercept = self.get_beta_GPs() long_legs_modify = [] for i in range(self.array_len): new_long_leg = long_legs[i] * self.beta &#43; self.intercept long_legs_modify.append(new_long_leg) _, p_value, _ = coint(long_legs_modify, short_legs) return p_value def generate_combinations(symbols): return list(combinations(symbols, 2)) p_value = 0.99 stop_loss = 0.5 def main(selected_symbols): cash = 1000000 transactionFeeRate = 0 start = &#39;2023-01-01&#39; end = &#39;2024-10-31&#39; broker = Broker(cash, transactionFeeRate, selected_symbols) setting = { &#39;short_leg&#39;: selected_symbols[0], &#39;long_leg&#39;: selected_symbols[1], &#39;open_margin&#39;: 0.05, &#39;close_margin&#39;: 0.02, &#39;stop_loss&#39;: stop_loss, &#39;pValue&#39;: 0.05, &#39;grid_amount&#39;: cash * 0.2, &#39;array_len&#39;: 300, &#39;maximum_holding_period&#39;: 300, } strategy = Cointegration(broker, setting) log = Log(broker) backtestor = BacktestorPairTrading(broker, strategy, log, start, end) backtestor.load_data() backtestor.run_backtest() result = backtestor.performance() msg_df = pd.DataFrame(broker.msg) profit, loss, winrate = analyze_arbitrage_cycles(msg_df) # msg_df.to_csv(&#39;backTestResult/msg_df.csv&#39;) pnl_ratio = profit / loss result[&#39;pnl_ratio&#39;] = pnl_ratio result[&#39;win_rate&#39;] = winrate return result # msg_df = pd.DataFrame(broker.msg) # msg_df.to_csv(&#39;backTestResult/msg_df.csv&#39;) if __name__ == &#39;__main__&#39;: from backTestResult.cointegration_analysis import analyze_arbitrage_cycles cash = 1000000 transactionFeeRate = 0.00025 start = &#39;2023-01-01&#39; end = &#39;2024-10-31&#39; long_leg = &#39;DOGE&#39; short_leg = &#39;XRP&#39; selected_symbols = [long_leg, short_leg] broker = Broker(cash, transactionFeeRate, selected_symbols) setting = { &#39;short_leg&#39;: short_leg, &#39;long_leg&#39;: long_leg, &#39;open_margin&#39;: 0.05, &#39;close_margin&#39;: 0.04, &#39;stop_loss&#39;: 0.4, &#39;pValue&#39;: 0.05, &#39;grid_amount&#39;: cash * 0.2, &#39;array_len&#39;: 200, &#39;maximum_holding_period&#39;: 24* 30, } strategy = Cointegration(broker, setting) log = Log(broker) backtestor = BacktestorPairTrading(broker, strategy, log, start, end) backtestor.load_data() backtestor.run_backtest() result = backtestor.performance() msg_df = pd.DataFrame(broker.msg) analyze_arbitrage_cycles(msg_df) msg_df.to_csv(&#39;backTestResult/msg_df.csv&#39;) Bayesian regression def bayesian_rolling_window(X_t, Y_t, window_size=30): T = len(X_t) beta_t_est = np.zeros(T) mu_t_est = np.zeros(T) beta_var_est = np.zeros(T) mu_var_est = np.zeros(T) residual_var_est = np.zeros(T) Y_pred = np.zeros(T) Y_std_est = np.zeros(T) # Prior parameters beta_mean_prior = 0 beta_var_prior = 1 mu_mean_prior = 0 mu_var_prior = 1 sigma_prior = 1 for t in range(window_size, T): # Get rolling window data X_window = np.float64(X_t[t - window_size:t]) Y_window = np.float64(Y_t[t - window_size:t]) # Posterior parameters for beta XTX = np.sum(X_window ** 2) XTY = np.sum(X_window * (Y_window - np.mean(Y_window))) beta_var_post = 1 / (1 / beta_var_prior &#43; XTX / sigma_prior) beta_mean_post = beta_var_post * (beta_mean_prior / beta_var_prior &#43; XTY / sigma_prior) # Posterior parameters for mu mu_var_post = 1 / (1 / mu_var_prior &#43; window_size / sigma_prior) mu_mean_post = mu_var_post * (mu_mean_prior / mu_var_prior &#43; np.sum(Y_window - beta_mean_post * X_window) / sigma_prior) # Estimate residual variance residuals_window = Y_window - (beta_mean_post * X_window &#43; mu_mean_post) residual_var_est[t] = np.var(residuals_window) # Store estimates beta_t_est[t] = beta_mean_post mu_t_est[t] = mu_mean_post beta_var_est[t] = beta_var_post mu_var_est[t] = mu_var_post # Predict Y_t and its credible interval Y_pred[t] = beta_t_est[t] * X_t[t] &#43; mu_t_est[t] Y_var_est = (X_t[t] ** 2) * (beta_var_est[t]) &#43; (mu_var_est[t]) &#43; (1 / sigma_prior) Y_std_est[t] = np.sqrt(Y_var_est) # Prior parameters beta_mean_prior = beta_mean_post beta_var_prior = beta_var_post mu_mean_prior = mu_mean_post mu_var_prior = mu_var_post residuals = Y_t - Y_pred data = { &#39;y&#39;: { &#39;mean&#39;: Y_pred, &#39;upper&#39;: Y_pred &#43; 1.96 * Y_std_est, &#39;lower&#39;: Y_pred - 1.96 * Y_std_est }, &#39;beta&#39;: { &#39;mean&#39;: beta_t_est, &#39;upper&#39;: beta_t_est &#43; 1.96 * np.sqrt(beta_var_est), &#39;lower&#39;: beta_t_est - 1.96 * np.sqrt(beta_var_est) }, &#39;mu&#39;: { &#39;mean&#39;: mu_t_est, &#39;upper&#39;: mu_t_est &#43; 1.96 * np.sqrt(mu_var_est), &#39;lower&#39;: mu_t_est - 1.96 * np.sqrt(mu_var_est) }, &#39;epsilon&#39;: { &#39;mean&#39;: residuals, &#39;upper&#39;: residuals &#43; 1.96 * np.sqrt(residual_var_est), &#39;lower&#39;: residuals - 1.96 * np.sqrt(residual_var_est) }, } return data Bayesian GAM def bayesian_gam_with_splines(X_t, Y_t, df=10): T = len(X_t) time = np.linspace(0, 1, T) # Design matrices for splines design_matrix = patsy.dmatrix(f&#34;bs(time, df={df}, degree=3)&#34;, {&#34;time&#34;: time}, return_type=&#39;dataframe&#39;) # Joint Bayesian Ridge Regression for beta_t and mu_t X_joint = np.hstack([np.multiply(design_matrix.values, X_t[:, None]), design_matrix.values]) model_joint = BayesianRidge() model_joint.fit(X_joint, Y_t) # Predict values with uncertainties Y_pred, Y_std = model_joint.predict(X_joint, return_std=True) # Separate beta_t and mu_t beta_t_est = design_matrix.values @ model_joint.coef_[:design_matrix.shape[1]] mu_t_est = design_matrix.values @ model_joint.coef_[design_matrix.shape[1]:] # Compute standard deviations for beta and mu coef_cov = np.linalg.inv(model_joint.alpha_ * np.eye(X_joint.shape[1]) &#43; model_joint.lambda_ * X_joint.T @ X_joint) beta_std_est = np.sqrt(np.sum((design_matrix.values @ coef_cov[:design_matrix.shape[1], :design_matrix.shape[1]]) * design_matrix.values, axis=1)) mu_std_est = np.sqrt(np.sum((design_matrix.values @ coef_cov[design_matrix.shape[1]:, design_matrix.shape[1]:]) * design_matrix.values, axis=1)) # Posterior variance of noise residual_var_est = 1 / model_joint.alpha_ # Posterior noise variance residuals = Y_t - Y_pred data = { &#39;y&#39;: { &#39;mean&#39;: Y_pred, &#39;upper&#39;: Y_pred &#43; 1.96 * Y_std, &#39;lower&#39;: Y_pred - 1.96 * Y_std }, &#39;beta&#39;: { &#39;mean&#39;: beta_t_est, &#39;upper&#39;: beta_t_est &#43; 1.96 * beta_std_est, &#39;lower&#39;: beta_t_est - 1.96 * beta_std_est }, &#39;mu&#39;: { &#39;mean&#39;: mu_t_est, &#39;upper&#39;: mu_t_est &#43; 1.96 * mu_std_est, &#39;lower&#39;: mu_t_est - 1.96 * mu_std_est }, &#39;epsilon&#39;: { &#39;mean&#39;: residuals, &#39;upper&#39;: residuals &#43; 1.96 * np.sqrt(residual_var_est), &#39;lower&#39;: residuals - 1.96 * np.sqrt(residual_var_est) }, } return data Gaussian Process class TimeVaryingGP(ExactGP): def __init__(self, train_x, train_y, likelihood): super(TimeVaryingGP, self).__init__(train_x, train_y, likelihood) # Separate kernels for each component self.beta_kernel = ScaleKernel(RBFKernel()) # self.beta_kernel.base_kernel.register_prior( # &#39;lengthscale_prior&#39;, # gpytorch.priors.GammaPrior(10.0, 20.0), # &#39;lengthscale&#39; # ) self.mu_kernel = ScaleKernel(RBFKernel()) self.eps_kernel = ScaleKernel(RBFKernel()) self.mean = ZeroMean() def forward(self, x): # Extract time and covariates t = x[:, 0] # time index X = x[:, 1] # covariate # Compute kernel matrices K_beta = self.beta_kernel(t) K_mu = self.mu_kernel(t) K_eps = self.eps_kernel(t) # Compute covariance matrix covar = X.unsqueeze(1) * K_beta * X.unsqueeze(0) &#43; K_mu &#43; K_eps mean = self.mean(x) return MultivariateNormal(mean, covar) def train_model(X, y, n_iter=100): if not isinstance(X, torch.Tensor): X = torch.from_numpy(X).clone().detach().float() y = torch.from_numpy(y).clone().detach().float() else: X = X.clone().detach().float() y = y.clone().detach().float() # Initialize model likelihood = gpytorch.likelihoods.GaussianLikelihood() model = TimeVaryingGP(X, y, likelihood) # Use the adam optimizer optimizer = torch.optim.Adam([ {&#39;params&#39;: model.parameters()}, ], lr=0.1) # &#34;Loss&#34; for GPs - the marginal log likelihood mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model) # Training loop model.train() likelihood.train() for i in range(n_iter): optimizer.zero_grad() output = model(X) loss = -mll(output, y) loss.backward() optimizer.step() return model, likelihood def predict_latent(model, X_train, y_train, X_new): model.eval() jitter = 1e-6 with torch.no_grad(): t_train = X_train[:, 0] x_train = X_train[:, 1] t_new = X_new[:, 0] x_new = X_new[:, 1] K_beta = model.beta_kernel(t_new, t_train).evaluate() K_mu = model.mu_kernel(t_new, t_train).evaluate() K_eps = model.eps_kernel(t_new, t_train).evaluate() K_total = x_train * model.beta_kernel(t_train).evaluate() * x_train.unsqueeze(-1) &#43; \ model.mu_kernel(t_train).evaluate() &#43; \ model.eps_kernel(t_train).evaluate() &#43; \ model.likelihood.noise * torch.eye(len(t_train)) &#43; \ jitter * torch.eye(len(t_train)) K_new_beta = model.beta_kernel(t_new).evaluate() &#43; jitter * torch.eye(len(t_new)) K_new_mu = model.mu_kernel(t_new).evaluate() &#43; jitter * torch.eye(len(t_new)) K_new_eps = model.eps_kernel(t_new).evaluate() &#43; jitter * torch.eye(len(t_new)) # Compute posterior mean using Cholesky L = torch.linalg.cholesky(K_total) alpha = torch.linalg.solve_triangular(L, y_train.unsqueeze(1), upper=False) alpha = torch.linalg.solve_triangular(L.T, alpha, upper=True) K_stacked = torch.stack([ x_new.unsqueeze(-1) * K_beta, K_mu, K_eps ]) posterior_mean = K_stacked @ alpha # Compute posterior variance using Cholesky v_beta = torch.linalg.solve_triangular(L, (x_train * K_beta.T).T, upper=False) v_mu = torch.linalg.solve_triangular(L, K_mu.T, upper=False) v_eps = torch.linalg.solve_triangular(L, K_eps.T, upper=False) post_var_beta = K_new_beta - v_beta.T @ v_beta post_var_mu = K_new_mu - v_mu.T @ v_mu post_var_eps = K_new_eps - v_eps.T @ v_eps return { &#39;mean&#39;: { &#39;beta&#39;: posterior_mean[0].squeeze(), &#39;mu&#39;: posterior_mean[1].squeeze(), &#39;epsilon&#39;: posterior_mean[2].squeeze() }, &#39;variance&#39;: { &#39;beta&#39;: post_var_beta.diag(), &#39;mu&#39;: post_var_mu.diag(), &#39;epsilon&#39;: post_var_eps.diag() } } def predict(model, likelihood, X_new, X_train=None, y_train=None): model.eval() likelihood.eval() if X_train is None: X_train = model.train_inputs[0] if y_train is None: y_train = model.train_targets with torch.no_grad(), gpytorch.settings.fast_pred_var(): observed_pred = likelihood(model(X_new)) latent_values = predict_latent(model, X_train, y_train, X_new) return observed_pred.mean, observed_pred.variance, latent_values BSTS def bsts_fit(x,y): with pm.Model() as model: # Priors for variances # sigma = pm.HalfCauchy(&#39;sigma&#39;, beta=1) # Random walk for log volatility log_sigma = pm.GaussianRandomWalk(&#39;log_sigma&#39;, sigma=0.1, shape=len(y), init_dist=pm.Normal.dist(mu=0, sigma=1)) sigma = pm.Deterministic(&#39;sigma&#39;, pm.math.exp(log_sigma)) sigma_beta = pm.HalfCauchy(&#39;sigma_beta&#39;, beta=1) sigma_mu = pm.HalfCauchy(&#39;sigma_mu&#39;, beta=1) # Gaussian Random Walks for beta and mu beta = pm.GaussianRandomWalk(&#39;beta&#39;, sigma=sigma_beta, init_dist=pm.Normal.dist(0, 10), shape=len(y)) mu = pm.GaussianRandomWalk(&#39;mu&#39;, sigma=sigma_mu, init_dist=pm.Normal.dist(0, 10), shape=len(y)) # Observation model Y_obs = pm.Normal(&#39;Y_obs&#39;, mu=beta * x &#43; mu, sigma=sigma, observed=y) # ---- 3. MCMC Sampling ---- trace = pm.sample(1000, tune=1000, chains=2, target_accept=0.9) ppc = pm.sample_posterior_predictive(trace, var_names=[&#34;Y_obs&#34;], random_seed=42) # Extract posterior mean and 95% credible intervals beta_posterior = trace.posterior[&#39;beta&#39;].mean(dim=(&#34;chain&#34;, &#34;draw&#34;)) beta_lower = trace.posterior[&#39;beta&#39;].quantile(0.025, dim=(&#34;chain&#34;, &#34;draw&#34;)) beta_upper = trace.posterior[&#39;beta&#39;].quantile(0.975, dim=(&#34;chain&#34;, &#34;draw&#34;)) mu_posterior = trace.posterior[&#39;mu&#39;].mean(dim=(&#34;chain&#34;, &#34;draw&#34;)) mu_lower = trace.posterior[&#39;mu&#39;].quantile(0.025, dim=(&#34;chain&#34;, &#34;draw&#34;)) mu_upper = trace.posterior[&#39;mu&#39;].quantile(0.975, dim=(&#34;chain&#34;, &#34;draw&#34;)) # Extract posterior predictive samples y_pred_samples = ppc.posterior_predictive[&#39;Y_obs&#39;] # Calculate mean and 95% prediction interval y_pred_mean = y_pred_samples.mean(dim=(&#39;chain&#39;, &#39;draw&#39;)).values y_pred_lower = np.percentile(y_pred_samples.values, 2.5, axis=(0, 1)) # 2.5% quantile y_pred_upper = np.percentile(y_pred_samples.values, 97.5, axis=(0, 1)) # 97.5% quantile epsilon_samples = y - y_pred_samples.values # Shape: (chains, draws, time) # ---- 3. Calculate Mean and Intervals ---- # Mean residuals epsilon_mean = epsilon_samples.mean(axis=(0, 1)) # Average over chains and draws # 95% prediction intervals epsilon_lower = np.percentile(epsilon_samples, 2.5, axis=(0, 1)) epsilon_upper = np.percentile(epsilon_samples, 97.5, axis=(0, 1)) data = { &#39;y&#39;: { &#39;mean&#39;: y_pred_mean, &#39;upper&#39;: y_pred_upper, &#39;lower&#39;: y_pred_lower }, &#39;beta&#39;: { &#39;mean&#39;: beta_posterior, &#39;upper&#39;: beta_upper, &#39;lower&#39;: beta_lower }, &#39;mu&#39;: { &#39;mean&#39;: mu_posterior, &#39;upper&#39;: mu_upper, &#39;lower&#39;: mu_lower }, &#39;epsilon&#39;: { &#39;mean&#39;: epsilon_mean, &#39;upper&#39;: epsilon_upper, &#39;lower&#39;: epsilon_lower }, } return data Gaussian Process clustering import pandas as pd import numpy as np from sklearn.cluster import KMeans import gpytorch import torch class SparseGPModel(gpytorch.models.ApproximateGP): def __init__(self, inducing_points): variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(0)) variational_strategy = gpytorch.variational.VariationalStrategy( self, inducing_points, variational_distribution, learn_inducing_locations=True ) super().__init__(variational_strategy) # Define kernel: RBF kernel with constant mean self.mean_module = gpytorch.means.ConstantMean() self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) def forward(self, x): mean_x = self.mean_module(x) covar_x = self.covar_module(x) return gpytorch.distributions.MultivariateNormal(mean_x, covar_x) def sparse_gpr_hyperparameter_clustering(data, n_clusters=3, num_inducing=10, verbose=True): symbols = data.iloc[:, 0].values time_points = torch.tensor(np.arange(data.shape[1] - 1), dtype=torch.float32) # Time indices time_series = torch.tensor(data.iloc[:, 1:].values, dtype=torch.float32) # Time series values # Initialize list to store hyperparameters hyperparameters = [] if verbose: print(&#34;Starting Sparse Gaussian Process Regression for each stock...\n&#34;) for idx, ts in enumerate(time_series): ts = ts.unsqueeze(-1) # Add a dimension for compatibility (n_samples, 1) inducing_points = time_points[::len(time_points) // num_inducing][:num_inducing].unsqueeze(-1) model = SparseGPModel(inducing_points) likelihood = gpytorch.likelihoods.GaussianLikelihood() model.train() likelihood.train() optimizer = torch.optim.Adam(model.parameters(), lr=0.1) mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=len(time_points)) # Training loop (simple with fixed iterations for now) training_iter = 100 # You can adjust this for i in range(training_iter): optimizer.zero_grad() output = model(time_points.unsqueeze(-1)) loss = -mll(output, ts).sum() loss.backward() optimizer.step() # Extract learned hyperparameters kernel_params = model.covar_module.base_kernel.lengthscale.item() outputscale = model.covar_module.outputscale.item() noise = likelihood.noise.item() hyperparameters.append([outputscale, kernel_params, noise]) if verbose: print(f&#34;Processed {idx &#43; 1}/{len(time_series)}: Symbol = {symbols[idx]}, &#34; f&#34;Output Scale = {outputscale:.3f}, Length Scale = {kernel_params:.3f}, noise = {noise:.3f}&#34;) if verbose: print(&#34;\nFinished Sparse Gaussian Process Regression.&#34;) print(&#34;Starting clustering on hyperparameters...\n&#34;) # Perform clustering on hyperparameters hyperparameters = np.array(hyperparameters) kmeans = KMeans(n_clusters=n_clusters, random_state=0) labels = kmeans.fit_predict(hyperparameters) clusters = {} for cluster_id in range(n_clusters): clusters[f&#39;Cluster{cluster_id&#43;1}&#39;] = symbols[labels == cluster_id].tolist() if verbose: print(f&#34;Cluster {cluster_id &#43; 1}: {len(clusters[f&#39;Cluster{cluster_id&#43;1}&#39;])} symbols&#34;) if verbose: print(&#34;\nClustering complete. Summary:&#34;) for cluster, symbols in clusters.items(): print(f&#34;{cluster}: {symbols}&#34;) return clusters df = pd.read_csv(&#39;Quantitative_Research/model_new/bayesian_clustering/transposed_stock_data.csv&#39;) clusters = sparse_gpr_hyperparameter_clustering(df, n_clusters=10, verbose=True) print(clusters) Appendix broker object class Broker: def __init__(self, cash: float, feeRate: float, symbols: list): self.positions = {} self.wallet = {} for symbol in symbols: self.wallet[symbol] = 0 self.cash = cash self.feeRate = feeRate self.totalFee = 0 self.symbols = symbols self.msg = [] def buy(self, price, symbol, vol): # cash = self.cash # if cash - price * vol * (1 &#43; self.feeRate) &lt; 0: # # print(&#34;not enough cash, but amount that minus fees&#34;) # vol -= price * vol * self.feeRate / price self.cash -= price * vol * (1 &#43; self.feeRate) self.wallet[symbol] &#43;= vol self.totalFee &#43;= price * vol * self.feeRate msg = f&#34;Buy {symbol} at price: {price} for {vol} amount&#34; print(msg) msg_dict = { &#34;symbol&#34;: symbol, &#34;price&#34;: price, &#34;vol&#34;: vol, &#34;action&#34;: &#34;buy&#34; } self.msg.append(msg_dict) def sell(self, price, symbol, vol): self.cash &#43;= price * vol * (1 - self.feeRate) self.wallet[symbol] -= vol self.totalFee &#43;= price * vol * self.feeRate msg = f&#34;Sell {symbol} at price: {price} for {vol} amount&#34; print(msg) msg_dict = { &#34;symbol&#34;: symbol, &#34;price&#34;: price, &#34;vol&#34;: vol, &#34;action&#34;: &#34;sell&#34; } self.msg.append(msg_dict) def _update_position(self, symbol, price, vol, direction, time): if symbol in self.positions: position = self.positions[symbol] if position.direction == direction: # 加仓，计算新的加权平均价格 new_volume = position.volume &#43; vol new_avg_price = (position.avg_price * position.volume &#43; price * vol) / new_volume position.avg_price = new_avg_price position.volume = new_volume position.time = time else: # 如果方向相反，考虑部分平仓或完全平仓的情况 if abs(position.volume) &gt; vol: # 部分平仓 position.volume -= vol elif abs(position.volume) == vol: # 完全平仓，删除仓位 del self.positions[symbol] else: # 平掉原仓位并开立新方向的仓位 new_vol = vol - abs(position.volume) position.direction = direction position.avg_price = price position.volume = new_vol position.time = time else: # 开立新仓位 self.positions[symbol] = Position(time=time, avg_price=price, symbol=symbol, direction=direction, volume=vol) def long(self, price, symbol, vol, leverage, time): &#34;&#34;&#34; 开立多头仓位，使用杠杆购买资产。 :param price: 当前资产价格 :param symbol: 资产符号 :param vol: 购买的资产数量 :param leverage: 杠杆倍数 :param time: 当前时间 &#34;&#34;&#34; margin_required = (price * vol) / leverage # if self.cash &lt; margin_required: # print(&#34;Not enough cash to open long position with leverage.&#34;) # return self.cash -= margin_required fee = price * vol * self.feeRate self.totalFee &#43;= fee self._update_position(symbol, price, vol * leverage, &#39;long&#39;, time) msg = f&#34;Long {symbol} at price: {price} for {vol} amount with leverage {leverage}&#34; print(msg) msg_dict = { &#34;symbol&#34;: symbol, &#34;price&#34;: price, &#34;vol&#34;: vol, &#34;action&#34;: &#34;long&#34; } self.msg.append(msg_dict) def short(self, price, symbol, vol, leverage, time): &#34;&#34;&#34; 开立空头仓位，使用杠杆卖出资产。 :param price: 当前资产价格 :param symbol: 资产符号 :param vol: 卖出的资产数量 :param leverage: 杠杆倍数 :param time: 当前时间 &#34;&#34;&#34; margin_required = (price * vol) / leverage # if self.cash &lt; margin_required: # print(&#34;Not enough cash to open short position with leverage.&#34;) # return self.cash -= margin_required fee = price * vol * self.feeRate self.totalFee &#43;= fee self._update_position(symbol, price, vol * leverage, &#39;short&#39;, time) msg = f&#34;Short {symbol} at price: {price} for {vol} amount with leverage {leverage}&#34; print(msg) msg_dict = { &#34;symbol&#34;: symbol, &#34;price&#34;: price, &#34;vol&#34;: vol, &#34;action&#34;: &#34;short&#34; } self.msg.append(msg_dict) def cover_long(self, price, symbol, vol, time): &#34;&#34;&#34; 平掉多头仓位。 :param price: 当前资产价格 :param symbol: 资产符号 :param vol: 平仓的资产数量 :param time: 当前时间 &#34;&#34;&#34; if symbol not in self.positions or self.positions[symbol].direction != &#39;long&#39;: print(&#34;No long position to cover.&#34;) return fee = price * vol * self.feeRate self.totalFee &#43;= fee position_worth = self.positions[symbol].avg_price * vol pnl = (price - self.positions[symbol].avg_price) * vol self.cash &#43;= pnl &#43; position_worth - fee self._update_position(symbol, price, vol, &#39;cover_long&#39;, time) msg = f&#34;Cover long {symbol} at price: {price} for {vol} amount&#34; print(msg) msg_dict = { &#34;symbol&#34;: symbol, &#34;price&#34;: price, &#34;vol&#34;: vol, &#34;action&#34;: &#34;cover long&#34; } self.msg.append(msg_dict) def cover_short(self, price, symbol, vol, time): &#34;&#34;&#34; 平掉空头仓位。 :param price: 当前资产价格 :param symbol: 资产符号 :param vol: 平仓的资产数量 :param time: 当前时间 &#34;&#34;&#34; if symbol not in self.positions or self.positions[symbol].direction != &#39;short&#39;: print(&#34;No short position to cover.&#34;) return fee = price * vol * self.feeRate self.totalFee &#43;= fee position_worth = self.positions[symbol].avg_price * vol pnl = (self.positions[symbol].avg_price - price) * vol self.cash &#43;= pnl &#43; position_worth - fee self._update_position(symbol, price, vol, &#39;cover_short&#39;, time) msg = f&#34;Cover short {symbol} at price: {price} for {vol} amount&#34; print(msg) msg_dict = { &#34;symbol&#34;: symbol, &#34;price&#34;: price, &#34;vol&#34;: vol, &#34;action&#34;: &#34;cover short&#34; } self.msg.append(msg_dict) def calculate_total_account_equity(self, current_prices: dict): &#34;&#34;&#34; 计算当前账户的总净值，包括现金和所有持仓的浮动盈亏。 :param current_prices: dict，包含每个资产的当前价格，例如：{&#34;BTC&#34;: 40000, &#34;ETH&#34;: 3000} &#34;&#34;&#34; total_pnl = 0 position_worth = 0 for symbol, position in self.positions.items(): if symbol in current_prices: current_price: BarData = current_prices[symbol] if position.direction == &#39;long&#39;: pnl = (current_price.close - position.avg_price) * position.volume elif position.direction == &#39;short&#39;: pnl = (position.avg_price - current_price.close) * position.volume position_worth &#43;= position.volume * position.avg_price total_pnl &#43;= pnl total_equity = self.cash &#43; total_pnl &#43; position_worth # print(f&#34;Total Account Equity: {total_equity:.2f} USD&#34;) return total_equity def get_current_pos_profit_rate(self, current_prices:dict): total_pnl = 0 position_worth = 0 for symbol, position in self.positions.items(): if symbol in current_prices: current_price: BarData = current_prices[symbol] if position.direction == &#39;long&#39;: pnl = (current_price.close - position.avg_price) * position.volume elif position.direction == &#39;short&#39;: pnl = (position.avg_price - current_price.close) * position.volume position_worth &#43;= position.volume * position.avg_price total_pnl &#43;= pnl profit_rate = total_pnl / position_worth return profit_rate ...</p>
  </div>
  <footer class="entry-footer"><span title='2025-01-25 19:12:16 +0100 CET'>January 25, 2025</span>&nbsp;·&nbsp;17 min</footer>
  <a class="entry-link" aria-label="post link to Bayesian Cointegration codes" href="https://oldhuntor.github.io/posts/codesnippets/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Trading strategies based on Bayesian theory (Part 3)
    </h2>
  </header>
  <div class="entry-content">
    <p>In the last essay we talked about using the Gamma-Poisson conjugate distribution to develop trading strategies. In the following article, we will try to use the more complex Dirichlet-Multinominal conjugate distribution.
What is Dirichlet Distribution The Dirichlet distribution is a family of continuous multivariate probability distributions parameterized by a positive real vector. It is often used as a prior distribution for multinomial distributions in Bayesian statistics. The formula for the probability density function of the Dirichlet distribution is as follows:
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-13 19:12:16 +0100 CET'>November 13, 2024</span>&nbsp;·&nbsp;8 min</footer>
  <a class="entry-link" aria-label="post link to Trading strategies based on Bayesian theory (Part 3)" href="https://oldhuntor.github.io/posts/dirichletmultinominal/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Trading strategies based on Bayesian theory (Part 2)
    </h2>
  </header>
  <div class="entry-content">
    <p>In the previous post we learned how to design trading strategies using the beta-binomial conjugate distribution. Can we design trading strategies using the gamma-Poisson conjugate distribution? This post will show an example of a trading strategy.
Model Objective: simulate the average number of increases over a period of time Prior distribution: gamma distribution, the following is the distribution function of gamma distribution: $$ f(x; \alpha, \beta) = \frac{\beta^{\alpha} x^{\alpha - 1} e^{-\beta x}}{\Gamma(\alpha)} $$ Below are the images of the gamma distribution function with different parameters:： It can be seen that the domain of the gamma distribution is [0, &#43;$\infty$], which means that we can no longer choose to study the parameter $\theta$, which is a 0 to 1 probability of increase. We can study the average number of increases $\lambda$ over a period of time. This is why we need to choose the Poisson distribution to calculate the likelihood.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-12 19:12:16 +0100 CET'>November 12, 2024</span>&nbsp;·&nbsp;9 min</footer>
  <a class="entry-link" aria-label="post link to Trading strategies based on Bayesian theory (Part 2)" href="https://oldhuntor.github.io/posts/poissongamma/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Trading strategies based on Bayesian theory (Part 1)
    </h2>
  </header>
  <div class="entry-content">
    <p>Model Logic Assuming that the long cycle can reflect the trend, and after observing the short-term data, we can better judge the long-term trend.
Goal: Predict whether there will be a trend in the future Parameter：$\theta$ ：The probability of rising is a float between 0 and 1. Model：Based on long-term data，Determine the prior distribution of $\theta$, and then update our belief in $\theta$ based on short-term data to obtain the posterior distribution. prior：Because $\theta$ is a continuous distribution from 0 to 1, we choose Beta distribution. likelihood：Because we want to predict the rise and fall, we can simplify the data to tossing a coin, which is a binomial distribution. beta - binomial conjugate, if beta distribution is used as the prior distribution and binomial distribution is used as the Siran function, then the posterior distribution is also beta distribution, which can simplify the calculation. Applying Bayesian theory $f(\theta)$ is the prior distribution prior $f(\theta|X)$ is the posterior distribution posterior $f(X|\theta)$ is the likelihood function ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-11 19:12:16 +0100 CET'>November 11, 2024</span>&nbsp;·&nbsp;5 min</footer>
  <a class="entry-link" aria-label="post link to Trading strategies based on Bayesian theory (Part 1)" href="https://oldhuntor.github.io/posts/betabinomial/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Grid trading application
    </h2>
  </header>
  <div class="entry-content">
    <p>Parameter Definition Strategy logic parameters upperPrice lowerPrice currentPrice gridStep gridAmount initPrice initAmount totalGrids tarPos baseCurrency quoteCurrency Strategy performance calculation startPrice initBase initQuote finalBase finalQuote initDate unilateral posAvg totalDays What’s grid trading Strategy usage background: after a big bullish market, the market starts to go bearish, that’s the right moment for using grid trading strategy. Just like the graph above, the green lines stand for buy limit orders, red lines stand for sell limit orders. The grid trading is just placing orders based on the current price, places sell orders at prices that are higher than current price, places buy orders at prices that are lower than current price. Assume that the price drop to 5, the limit buy order at 5 would be executed, we replenish another sell order at 5.1, the orders list would like the above graphs. The reverse situation would be the same, so during a market where the volatility is high, this strategy can generate profit.
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-06-21 19:12:16 +0100 +0100'>June 21, 2021</span>&nbsp;·&nbsp;13 min</footer>
  <a class="entry-link" aria-label="post link to Grid trading application" href="https://oldhuntor.github.io/posts/gridtrading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Event driven trading system
    </h2>
  </header>
  <div class="entry-content">
    <p>Event driven trading system This article is inspired by VNPY, which is available under the MIT License. And the official ByBit python SDK PyBit.
Algorithmic trading has inspired many people to implement their strategies. It frees the hands of the traders and materialize doesn’t suffer from the human emotion.
Here I will introduce an event-driven trading system: Websocket and Rest API As the graph above shows, we have two data sources which are websocket and rest api, we usually use websocket API for market data stream since it’s a long connection, and we use Rest API for sending order and it’s a quick one time connection, but the function from these two types of API are interchangable.
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-06-09 19:12:16 +0100 +0100'>June 9, 2021</span>&nbsp;·&nbsp;6 min</footer>
  <a class="entry-link" aria-label="post link to Event driven trading system" href="https://oldhuntor.github.io/posts/event_driven_trading_system/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">About me
    </h2>
  </header>
  <div class="entry-content">
    <p>Education Background TU dortmund 10/2022 - till now
Major M.Sc. Data Science
Beijng Institute of Technology, Zhuhai 2016 - 2020
Major B.Sc. Applied Statistics
Work Experience Beijing FengYunTianDi (2021) Job title: Data Analyst Python
Geometry data analysis using Geopandas Radar data preprocessing, automatic alarm system for power grid Alarming strategy developing Guangdong Molecular Assets Management Co., Ltd. (2021-2022) Job title: Quantitative Trading Engineer
Developing testing and maintaining hedging and grid trading strategy Market data scrapping and analysis Backtesting framework development Research assisstant in TU dortmund (2024-2025) Hyper parameter tuning method research Experiment data analysis Testfunction modification TOPSEC (Internship) (2019) Intern in the After-sales department Push products: issued data leak prevention software to users by company’s server Prize Mathematical Contest in Modeling (Honorable Mention Winner 2019)
...</p>
  </div>
  <footer class="entry-footer"><span title='2020-02-08 19:12:16 +0100 CET'>February 8, 2020</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to About me" href="https://oldhuntor.github.io/posts/about-me/"></a>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://oldhuntor.github.io/">Xuanhao&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
