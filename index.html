<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
	<meta name="generator" content="Hugo 0.138.0"><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Xuanhao&#39;s Blog</title>

<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="https://oldhuntor.github.io/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://oldhuntor.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://oldhuntor.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://oldhuntor.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://oldhuntor.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://oldhuntor.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://oldhuntor.github.io/index.xml">
<link rel="alternate" hreflang="en" href="https://oldhuntor.github.io/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://oldhuntor.github.io/">
  <meta property="og:site_name" content="Xuanhao&#39;s Blog">
  <meta property="og:title" content="Xuanhao&#39;s Blog">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Xuanhao&#39;s Blog">
<meta name="twitter:description" content="">

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "Xuanhao's Blog",
  "url": "https://oldhuntor.github.io/",
  "description": "",
  "logo": "https://oldhuntor.github.io/favicon.ico",
  "sameAs": [
      "https://github.com/Oldhuntor", "https://blog.csdn.net/weixin_40264579/category_10737480.html"
  ]
}
</script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.13/katex.min.css">
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.13/katex.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.13/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body);"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
          ]
        });
      });
    </script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://oldhuntor.github.io/" accesskey="h" title="Xuanhao&#39;s Blog (Alt + H)">Xuanhao&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://oldhuntor.github.io/pdfs/xxx.pdf" title="My CV">
                    <span>My CV</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<article class="first-entry home-info">
    <header class="entry-header">
        <h1>Welcome to my techblogs! ğŸ’»ğŸ“ˆâ‚¿</h1>
    </header>
    <div class="entry-content">
        TU dortmund Msc. Data Science
    </div>
    <footer class="entry-footer">
        <div class="social-icons" >
    <a href="https://github.com/Oldhuntor" target="_blank" rel="noopener noreferrer me"
        title="Github">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
    </a>
    <a href="https://blog.csdn.net/weixin_40264579/category_10737480.html" target="_blank" rel="noopener noreferrer me"
        title="CSDN">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
    <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
</svg>
    </a>
</div>

    </footer>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Bayesian Cointegration codes
    </h2>
  </header>
  <div class="entry-content">
    <p>Bayesian regression def bayesian_rolling_window(X_t, Y_t, window_size=30): T = len(X_t) beta_t_est = np.zeros(T) mu_t_est = np.zeros(T) beta_var_est = np.zeros(T) mu_var_est = np.zeros(T) residual_var_est = np.zeros(T) Y_pred = np.zeros(T) Y_std_est = np.zeros(T) # Prior parameters beta_mean_prior = 0 beta_var_prior = 1 mu_mean_prior = 0 mu_var_prior = 1 sigma_prior = 1 for t in range(window_size, T): # Get rolling window data X_window = np.float64(X_t[t - window_size:t]) Y_window = np.float64(Y_t[t - window_size:t]) # Posterior parameters for beta XTX = np.sum(X_window ** 2) XTY = np.sum(X_window * (Y_window - np.mean(Y_window))) beta_var_post = 1 / (1 / beta_var_prior &#43; XTX / sigma_prior) beta_mean_post = beta_var_post * (beta_mean_prior / beta_var_prior &#43; XTY / sigma_prior) # Posterior parameters for mu mu_var_post = 1 / (1 / mu_var_prior &#43; window_size / sigma_prior) mu_mean_post = mu_var_post * (mu_mean_prior / mu_var_prior &#43; np.sum(Y_window - beta_mean_post * X_window) / sigma_prior) # Estimate residual variance residuals_window = Y_window - (beta_mean_post * X_window &#43; mu_mean_post) residual_var_est[t] = np.var(residuals_window) # Store estimates beta_t_est[t] = beta_mean_post mu_t_est[t] = mu_mean_post beta_var_est[t] = beta_var_post mu_var_est[t] = mu_var_post # Predict Y_t and its credible interval Y_pred[t] = beta_t_est[t] * X_t[t] &#43; mu_t_est[t] Y_var_est = (X_t[t] ** 2) * (beta_var_est[t]) &#43; (mu_var_est[t]) &#43; (1 / sigma_prior) Y_std_est[t] = np.sqrt(Y_var_est) # Prior parameters beta_mean_prior = beta_mean_post beta_var_prior = beta_var_post mu_mean_prior = mu_mean_post mu_var_prior = mu_var_post residuals = Y_t - Y_pred data = { &#39;y&#39;: { &#39;mean&#39;: Y_pred, &#39;upper&#39;: Y_pred &#43; 1.96 * Y_std_est, &#39;lower&#39;: Y_pred - 1.96 * Y_std_est }, &#39;beta&#39;: { &#39;mean&#39;: beta_t_est, &#39;upper&#39;: beta_t_est &#43; 1.96 * np.sqrt(beta_var_est), &#39;lower&#39;: beta_t_est - 1.96 * np.sqrt(beta_var_est) }, &#39;mu&#39;: { &#39;mean&#39;: mu_t_est, &#39;upper&#39;: mu_t_est &#43; 1.96 * np.sqrt(mu_var_est), &#39;lower&#39;: mu_t_est - 1.96 * np.sqrt(mu_var_est) }, &#39;epsilon&#39;: { &#39;mean&#39;: residuals, &#39;upper&#39;: residuals &#43; 1.96 * np.sqrt(residual_var_est), &#39;lower&#39;: residuals - 1.96 * np.sqrt(residual_var_est) }, } return data Bayesian GAM def bayesian_gam_with_splines(X_t, Y_t, df=10): T = len(X_t) time = np.linspace(0, 1, T) # Design matrices for splines design_matrix = patsy.dmatrix(f&#34;bs(time, df={df}, degree=3)&#34;, {&#34;time&#34;: time}, return_type=&#39;dataframe&#39;) # Joint Bayesian Ridge Regression for beta_t and mu_t X_joint = np.hstack([np.multiply(design_matrix.values, X_t[:, None]), design_matrix.values]) model_joint = BayesianRidge() model_joint.fit(X_joint, Y_t) # Predict values with uncertainties Y_pred, Y_std = model_joint.predict(X_joint, return_std=True) # Separate beta_t and mu_t beta_t_est = design_matrix.values @ model_joint.coef_[:design_matrix.shape[1]] mu_t_est = design_matrix.values @ model_joint.coef_[design_matrix.shape[1]:] # Compute standard deviations for beta and mu coef_cov = np.linalg.inv(model_joint.alpha_ * np.eye(X_joint.shape[1]) &#43; model_joint.lambda_ * X_joint.T @ X_joint) beta_std_est = np.sqrt(np.sum((design_matrix.values @ coef_cov[:design_matrix.shape[1], :design_matrix.shape[1]]) * design_matrix.values, axis=1)) mu_std_est = np.sqrt(np.sum((design_matrix.values @ coef_cov[design_matrix.shape[1]:, design_matrix.shape[1]:]) * design_matrix.values, axis=1)) # Posterior variance of noise residual_var_est = 1 / model_joint.alpha_ # Posterior noise variance residuals = Y_t - Y_pred data = { &#39;y&#39;: { &#39;mean&#39;: Y_pred, &#39;upper&#39;: Y_pred &#43; 1.96 * Y_std, &#39;lower&#39;: Y_pred - 1.96 * Y_std }, &#39;beta&#39;: { &#39;mean&#39;: beta_t_est, &#39;upper&#39;: beta_t_est &#43; 1.96 * beta_std_est, &#39;lower&#39;: beta_t_est - 1.96 * beta_std_est }, &#39;mu&#39;: { &#39;mean&#39;: mu_t_est, &#39;upper&#39;: mu_t_est &#43; 1.96 * mu_std_est, &#39;lower&#39;: mu_t_est - 1.96 * mu_std_est }, &#39;epsilon&#39;: { &#39;mean&#39;: residuals, &#39;upper&#39;: residuals &#43; 1.96 * np.sqrt(residual_var_est), &#39;lower&#39;: residuals - 1.96 * np.sqrt(residual_var_est) }, } return data Gaussian Process class TimeVaryingGP(ExactGP): def __init__(self, train_x, train_y, likelihood): super(TimeVaryingGP, self).__init__(train_x, train_y, likelihood) # Separate kernels for each component self.beta_kernel = ScaleKernel(RBFKernel()) # self.beta_kernel.base_kernel.register_prior( # &#39;lengthscale_prior&#39;, # gpytorch.priors.GammaPrior(10.0, 20.0), # &#39;lengthscale&#39; # ) self.mu_kernel = ScaleKernel(RBFKernel()) self.eps_kernel = ScaleKernel(RBFKernel()) self.mean = ZeroMean() def forward(self, x): # Extract time and covariates t = x[:, 0] # time index X = x[:, 1] # covariate # Compute kernel matrices K_beta = self.beta_kernel(t) K_mu = self.mu_kernel(t) K_eps = self.eps_kernel(t) # Compute covariance matrix covar = X.unsqueeze(1) * K_beta * X.unsqueeze(0) &#43; K_mu &#43; K_eps mean = self.mean(x) return MultivariateNormal(mean, covar) def train_model(X, y, n_iter=100): if not isinstance(X, torch.Tensor): X = torch.from_numpy(X).clone().detach().float() y = torch.from_numpy(y).clone().detach().float() else: X = X.clone().detach().float() y = y.clone().detach().float() # Initialize model likelihood = gpytorch.likelihoods.GaussianLikelihood() model = TimeVaryingGP(X, y, likelihood) # Use the adam optimizer optimizer = torch.optim.Adam([ {&#39;params&#39;: model.parameters()}, ], lr=0.1) # &#34;Loss&#34; for GPs - the marginal log likelihood mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model) # Training loop model.train() likelihood.train() for i in range(n_iter): optimizer.zero_grad() output = model(X) loss = -mll(output, y) loss.backward() optimizer.step() return model, likelihood def predict_latent(model, X_train, y_train, X_new): model.eval() jitter = 1e-6 with torch.no_grad(): t_train = X_train[:, 0] x_train = X_train[:, 1] t_new = X_new[:, 0] x_new = X_new[:, 1] K_beta = model.beta_kernel(t_new, t_train).evaluate() K_mu = model.mu_kernel(t_new, t_train).evaluate() K_eps = model.eps_kernel(t_new, t_train).evaluate() K_total = x_train * model.beta_kernel(t_train).evaluate() * x_train.unsqueeze(-1) &#43; \ model.mu_kernel(t_train).evaluate() &#43; \ model.eps_kernel(t_train).evaluate() &#43; \ model.likelihood.noise * torch.eye(len(t_train)) &#43; \ jitter * torch.eye(len(t_train)) K_new_beta = model.beta_kernel(t_new).evaluate() &#43; jitter * torch.eye(len(t_new)) K_new_mu = model.mu_kernel(t_new).evaluate() &#43; jitter * torch.eye(len(t_new)) K_new_eps = model.eps_kernel(t_new).evaluate() &#43; jitter * torch.eye(len(t_new)) # Compute posterior mean using Cholesky L = torch.linalg.cholesky(K_total) alpha = torch.linalg.solve_triangular(L, y_train.unsqueeze(1), upper=False) alpha = torch.linalg.solve_triangular(L.T, alpha, upper=True) K_stacked = torch.stack([ x_new.unsqueeze(-1) * K_beta, K_mu, K_eps ]) posterior_mean = K_stacked @ alpha # Compute posterior variance using Cholesky v_beta = torch.linalg.solve_triangular(L, (x_train * K_beta.T).T, upper=False) v_mu = torch.linalg.solve_triangular(L, K_mu.T, upper=False) v_eps = torch.linalg.solve_triangular(L, K_eps.T, upper=False) post_var_beta = K_new_beta - v_beta.T @ v_beta post_var_mu = K_new_mu - v_mu.T @ v_mu post_var_eps = K_new_eps - v_eps.T @ v_eps return { &#39;mean&#39;: { &#39;beta&#39;: posterior_mean[0].squeeze(), &#39;mu&#39;: posterior_mean[1].squeeze(), &#39;epsilon&#39;: posterior_mean[2].squeeze() }, &#39;variance&#39;: { &#39;beta&#39;: post_var_beta.diag(), &#39;mu&#39;: post_var_mu.diag(), &#39;epsilon&#39;: post_var_eps.diag() } } def predict(model, likelihood, X_new, X_train=None, y_train=None): model.eval() likelihood.eval() if X_train is None: X_train = model.train_inputs[0] if y_train is None: y_train = model.train_targets with torch.no_grad(), gpytorch.settings.fast_pred_var(): observed_pred = likelihood(model(X_new)) latent_values = predict_latent(model, X_train, y_train, X_new) return observed_pred.mean, observed_pred.variance, latent_values BSTS def bsts_fit(x,y): with pm.Model() as model: # Priors for variances # sigma = pm.HalfCauchy(&#39;sigma&#39;, beta=1) # Random walk for log volatility log_sigma = pm.GaussianRandomWalk(&#39;log_sigma&#39;, sigma=0.1, shape=len(y), init_dist=pm.Normal.dist(mu=0, sigma=1)) sigma = pm.Deterministic(&#39;sigma&#39;, pm.math.exp(log_sigma)) sigma_beta = pm.HalfCauchy(&#39;sigma_beta&#39;, beta=1) sigma_mu = pm.HalfCauchy(&#39;sigma_mu&#39;, beta=1) # Gaussian Random Walks for beta and mu beta = pm.GaussianRandomWalk(&#39;beta&#39;, sigma=sigma_beta, init_dist=pm.Normal.dist(0, 10), shape=len(y)) mu = pm.GaussianRandomWalk(&#39;mu&#39;, sigma=sigma_mu, init_dist=pm.Normal.dist(0, 10), shape=len(y)) # Observation model Y_obs = pm.Normal(&#39;Y_obs&#39;, mu=beta * x &#43; mu, sigma=sigma, observed=y) # ---- 3. MCMC Sampling ---- trace = pm.sample(1000, tune=1000, chains=2, target_accept=0.9) ppc = pm.sample_posterior_predictive(trace, var_names=[&#34;Y_obs&#34;], random_seed=42) # Extract posterior mean and 95% credible intervals beta_posterior = trace.posterior[&#39;beta&#39;].mean(dim=(&#34;chain&#34;, &#34;draw&#34;)) beta_lower = trace.posterior[&#39;beta&#39;].quantile(0.025, dim=(&#34;chain&#34;, &#34;draw&#34;)) beta_upper = trace.posterior[&#39;beta&#39;].quantile(0.975, dim=(&#34;chain&#34;, &#34;draw&#34;)) mu_posterior = trace.posterior[&#39;mu&#39;].mean(dim=(&#34;chain&#34;, &#34;draw&#34;)) mu_lower = trace.posterior[&#39;mu&#39;].quantile(0.025, dim=(&#34;chain&#34;, &#34;draw&#34;)) mu_upper = trace.posterior[&#39;mu&#39;].quantile(0.975, dim=(&#34;chain&#34;, &#34;draw&#34;)) # Extract posterior predictive samples y_pred_samples = ppc.posterior_predictive[&#39;Y_obs&#39;] # Calculate mean and 95% prediction interval y_pred_mean = y_pred_samples.mean(dim=(&#39;chain&#39;, &#39;draw&#39;)).values y_pred_lower = np.percentile(y_pred_samples.values, 2.5, axis=(0, 1)) # 2.5% quantile y_pred_upper = np.percentile(y_pred_samples.values, 97.5, axis=(0, 1)) # 97.5% quantile epsilon_samples = y - y_pred_samples.values # Shape: (chains, draws, time) # ---- 3. Calculate Mean and Intervals ---- # Mean residuals epsilon_mean = epsilon_samples.mean(axis=(0, 1)) # Average over chains and draws # 95% prediction intervals epsilon_lower = np.percentile(epsilon_samples, 2.5, axis=(0, 1)) epsilon_upper = np.percentile(epsilon_samples, 97.5, axis=(0, 1)) data = { &#39;y&#39;: { &#39;mean&#39;: y_pred_mean, &#39;upper&#39;: y_pred_upper, &#39;lower&#39;: y_pred_lower }, &#39;beta&#39;: { &#39;mean&#39;: beta_posterior, &#39;upper&#39;: beta_upper, &#39;lower&#39;: beta_lower }, &#39;mu&#39;: { &#39;mean&#39;: mu_posterior, &#39;upper&#39;: mu_upper, &#39;lower&#39;: mu_lower }, &#39;epsilon&#39;: { &#39;mean&#39;: epsilon_mean, &#39;upper&#39;: epsilon_upper, &#39;lower&#39;: epsilon_lower }, } return data </p>
  </div>
  <footer class="entry-footer"><span title='2025-01-25 19:12:16 +0100 CET'>January 25, 2025</span>&nbsp;Â·&nbsp;6 min</footer>
  <a class="entry-link" aria-label="post link to Bayesian Cointegration codes" href="https://oldhuntor.github.io/posts/codesnippets/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Bayesian Cointegration
    </h2>
  </header>
  <div class="entry-content">
    <p>Bayesian Approach to Cointegration Pair Trading Methodology In this research, a Bayesian framework is utilized to model the dynamic relationship between two assets to identify profitable pair trading opportunities. The methodology consists of these steps:
Identifying Cointegrated Pairs:
Use historical price data to test for cointegration between asset pairs using statistical tests such as the Engle-Granger test or Johansen test.
Select pairs that demonstrate a strong cointegration relationship.
Additionally, using the fitting criterion of GPs and evaluate how strong the dependencies between pairs of assets:
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-12-08 19:12:16 +0100 CET'>December 8, 2024</span>&nbsp;Â·&nbsp;3 min</footer>
  <a class="entry-link" aria-label="post link to Bayesian Cointegration" href="https://oldhuntor.github.io/posts/bayesian_cointegration/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Non_conjugated Prior
    </h2>
  </header>
  <div class="entry-content">
    <p>åŸºäºè´å¶æ–¯ç†è®ºçš„äº¤æ˜“ç­–ç•¥ï¼ˆå››ï¼‰ å‰å‡ æœŸçš„æ–‡ç« éƒ½æ˜¯ç”¨å…±è½­å…ˆéªŒåˆ†å¸ƒæ¥åˆ¶å®šäº¤æ˜“ç­–ç•¥ï¼Œæœ¬æœŸæ–‡ç« å°†é‡‡ç”¨éå…±è½­åˆ†å¸ƒæ¥åˆ¶å®šäº¤æ˜“ç­–ç•¥ã€‚ ä¸€èˆ¬æƒ…å†µä¸‹æˆ‘ä»¬ç”¨æ­£å¤ªåˆ†å¸ƒå¯ä»¥æ‹Ÿåˆå¤§éƒ¨åˆ†ç±»å‹çš„æ•°æ®ï¼š ä½†ç°åœ¨æˆ‘ä»¬ä¸æƒ³å‡è®¾å…ˆéªŒåˆ†å¸ƒå±äºä»€ä¹ˆåˆ†å¸ƒï¼Œæˆ‘ä»¬æƒ³åˆ©ç”¨æ•°æ®æœ¬èº«ç›´æ¥å¾—å‡ºä¸€ä¸ªåˆ†å¸ƒï¼Œç±»ä¼¼äºæ— ç›‘ç£å­¦ä¹ ã€‚ æˆ‘ä»¬çš„åˆ†å¸ƒå¯ä»¥æ˜¯ä¸€ä¸ªæ›²çº¿æ¯”å¦‚ï¼š å¯¹äºè¿™ç§éé’Ÿå½¢æ›²çº¿ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨Gaussian mixture distributionå»æ‹Ÿåˆã€‚ Gaussian mixture distribution å³æ˜¯ä¸åŒå‚æ•°çš„é«˜æ–¯åˆ†å¸ƒç›¸åŠ åœ¨ä¸€èµ·ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå¤æ‚çš„æ•°æ®éœ€è¦çš„Gaussian mixture componentä¸ä¼šè¶…è¿‡5å°±èƒ½è¾¾åˆ°æ¯”è¾ƒå¥½çš„æ•ˆæœï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨AICå’ŒBICæ¥ç­›é€‰åˆé€‚çš„componentæ•°é‡ã€‚ ä»¥ä¸‹æ˜¯ä¸€ä¸ªpythonä¾‹å­ï¼š
from sklearn.mixture import GaussianMixture import numpy as np import matplotlib.pyplot as plt # ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨æ­£æ€åˆ†å¸ƒçš„éšæœºæ•°æ® data = np.random.normal(0, 1, 1000).reshape(-1, 1) # å°è¯•ä¸åŒçš„ç»„ä»¶æ•°é‡ï¼Œä»¥æ‰¾å‡ºæœ€ä½³çš„æ¨¡å‹ n_components_range = range(1, 11) models = [GaussianMixture(n, covariance_type=&#39;full&#39;, random_state=0).fit(data) for n in n_components_range] # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„AICå’ŒBIC aics = [m.aic(data) for m in models] bics = [m.bic(data) for m in models] # ç»˜åˆ¶AICå’ŒBICå›¾è¡¨ï¼Œä»¥é€‰æ‹©æœ€ä½³çš„ç»„ä»¶æ•°é‡ plt.figure(figsize=(10, 5)) plt.plot(n_components_range, aics, label=&#39;AIC&#39;, marker=&#39;o&#39;) plt.plot(n_components_range, bics, label=&#39;BIC&#39;, marker=&#39;o&#39;) plt.xlabel(&#39;Number of components&#39;) plt.ylabel(&#39;Information criterion&#39;) plt.legend() plt.title(&#39;AIC and BIC for different number of components&#39;) plt.show() # æ‰¾å‡ºAICå’ŒBICæœ€å°å€¼å¯¹åº”çš„ç»„ä»¶æ•°é‡ best_aic_n_components = n_components_range[np.argmin(aics)] best_bic_n_components = n_components_range[np.argmin(bics)] (best_aic_n_components, best_bic_n_components) è¿è¡Œç»“æœï¼š ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-20 19:12:16 +0100 CET'>November 20, 2024</span>&nbsp;Â·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Non_conjugated Prior" href="https://oldhuntor.github.io/posts/non_conjugation/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">BetaBinomial
    </h2>
  </header>
  <div class="entry-content">
    <p>åŸºäºè´å¶æ–¯ç†è®ºçš„äº¤æ˜“ç­–ç•¥ @TOC
æ¨¡å‹é€»è¾‘ å‡è®¾é•¿å‘¨æœŸæ˜¯èƒ½å¤Ÿä½“ç°è¶‹åŠ¿çš„ï¼Œå¹¶ä¸”å†è§‚æµ‹äº†çŸ­å‘¨æœŸçš„æ•°æ®ä¹‹åï¼Œèƒ½å¤Ÿæ›´å¥½çš„å¯¹é•¿å‘¨æœŸçš„è¶‹åŠ¿ä½œå‡ºåˆ¤æ–­ã€‚
ç›®æ ‡ï¼š é¢„æµ‹æœªæ¥æ˜¯å¦æœ‰è¶‹åŠ¿ å‚æ•°ï¼š$\theta$ ï¼šä¸Šæ¶¨çš„æ¦‚ç‡ï¼Œæ˜¯ä¸€ä¸ª0åˆ°1çš„float æ¨¡å‹ï¼šæ ¹æ®é•¿å‘¨æœŸæ•°æ®ï¼Œå†³å®š$\theta$ çš„å…ˆéªŒåˆ†å¸ƒï¼Œå†æ ¹æ®çŸ­å‘¨æœŸæ•°æ®ï¼Œæ›´æ–°æˆ‘ä»¬å¯¹$\theta$ çš„ä¿¡å¿µå¾—åˆ°åéªŒåˆ†å¸ƒã€‚ å…ˆéªŒåˆ†å¸ƒï¼ˆpriorï¼‰çš„é€‰æ‹©ï¼šå› ä¸º$\theta$ æ˜¯0åˆ°1çš„è¿ç»­åˆ†å¸ƒï¼Œäºæ˜¯æˆ‘ä»¬é€‰æ‹©Betaåˆ†å¸ƒã€‚ æ–¯ç„¶å‡½æ•°ï¼ˆlikelihoodï¼‰çš„é€‰æ‹©ï¼šå› ä¸ºæˆ‘ä»¬æƒ³é¢„æµ‹æ¶¨è·Œï¼Œå¯ä»¥æŠŠæ•°æ®ç®€åŒ–æˆæŠ›ç¡¬å¸ï¼Œå³æ˜¯äºŒé¡¹åˆ†å¸ƒã€‚ beta - binomial å…±è½­ï¼Œå¦‚æœä»¥betaåˆ†å¸ƒä¸ºå…ˆéªŒåˆ†å¸ƒï¼ŒäºŒé¡¹åˆ†å¸ƒä¸ºæ–¯ç„¶å‡½æ•°ï¼Œåˆ™åéªŒåˆ†å¸ƒä¹Ÿä¸ºbetaåˆ†å¸ƒï¼Œè¿™æ ·å­èƒ½å¤Ÿç®€åŒ–è®¡ç®—ã€‚ å¥—ç”¨è´å¶æ–¯ç†è®º $f(\theta)$ ä¸ºå…ˆéªŒåˆ†å¸ƒ prior $f(\theta|X)$ ä¸ºåéªŒåˆ†å¸ƒ posterior $f(X|\theta)$ ä¸ºæ–¯ç„¶å‡½æ•° likelihood $$f(\theta|X) = \frac{f(X|\theta) \cdot f(\theta)}{\int f(X|\theta) \cdot f(\theta) \, d\theta}$$æ ¹æ®æˆ‘ä»¬æ¨¡å‹çš„å‡è®¾ï¼Œ $\theta$ ï¼ˆä¸Šæ¶¨çš„æ¦‚ç‡ï¼Œopenå°äºcloseçš„æ¦‚ç‡ï¼‰ç¬¦åˆbetaåˆ†å¸ƒã€‚betaåˆ†å¸ƒçš„å½¢çŠ¶å‚æ•°$\alpha$ä¸ºé•¿å‘¨æœŸåºåˆ—ä¸­ï¼Œopenå°äºcloseä»·æ ¼çš„kçº¿çš„ä¸ªæ•°ï¼Œ$\beta$ä¸ºopenå¤§äºcloseä»·æ ¼çš„kçº¿çš„ä¸ªæ•°ã€‚ Betaåˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼š $$\text{Beta}(\theta | \alpha, \beta) = \frac{\theta^{\alpha - 1} (1 - \theta)^{\beta - 1}}{B(\alpha, \beta)}$$ æ–¯ç„¶å‡½æ•°ç¬¦åˆäºŒé¡¹åˆ†å¸ƒï¼Œ$n$ä¸ºçŸ­å‘¨æœŸåºåˆ—çš„é•¿åº¦ï¼Œ$k$ä¸ºopenå°äºcloseä»·æ ¼çš„kçº¿çš„ä¸ªæ•°ï¼š $$\text{Binomial}(k | n, \theta) = \binom{n}{k} \theta^k (1 - \theta)^{n-k}$$ æ ¹æ®è´å¶æ–¯å…¬å¼è®¡ç®—åå¾—åˆ°åéªŒåˆ†å¸ƒçš„å‚æ•°ï¼š $$ \alpha_{\text{post}} = \alpha &#43; k, \beta_{\text{post}} = \beta &#43; n - k$$ æ‰€ä»¥åéªŒåˆ†å¸ƒä¸ºï¼š ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-13 19:12:16 +0100 CET'>November 13, 2024</span>&nbsp;Â·&nbsp;2 min</footer>
  <a class="entry-link" aria-label="post link to BetaBinomial" href="https://oldhuntor.github.io/posts/betabinomial/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">DirichletMultinominal
    </h2>
  </header>
  <div class="entry-content">
    <p>åŸºäºè´å¶æ–¯ç†è®ºçš„äº¤æ˜“ç­–ç•¥ ï¼ˆä¸‰ï¼‰ ä¸Šä¸€ç¯‡æ–‡ç« æˆ‘ä»¬è®²äº†åˆ©ç”¨Gamma-Poissonå…±è½­åˆ†å¸ƒæ¥åˆ¶å®šäº¤æ˜“ç­–ç•¥ï¼Œä»¥ä¸‹è¿™ç¯‡æ–‡ç« æˆ‘ä»¬å°†å°è¯•ä½¿ç”¨æ›´åŠ å¤æ‚çš„Dirichlet-Multinominal å…±è½­åˆ†å¸ƒã€‚
ä»€ä¹ˆæ˜¯Dirichletåˆ†å¸ƒ Dirichletåˆ†å¸ƒæ˜¯ç”±æ­£å®æ•°å‘é‡å‚æ•°åŒ–çš„ä¸€ç³»åˆ—è¿ç»­å¤šå…ƒæ¦‚ç‡åˆ†å¸ƒã€‚ å®ƒç»å¸¸åœ¨è´å¶æ–¯ç»Ÿè®¡ä¸­ç”¨ä½œå¤šé¡¹åˆ†å¸ƒçš„å…ˆéªŒåˆ†å¸ƒã€‚ Dirichletåˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°çš„å…¬å¼å¦‚ä¸‹ï¼š
$$ P(\mathbf{x} \mid \boldsymbol{\alpha}) = \frac{1}{B(\boldsymbol{\alpha})} \prod_{i=1}^{K} x_i^{\alpha_i - 1} $$å…¶ä¸­$\mathbf{x} = (x_1, \ldots, x_K)$æ˜¯ä¸€ä¸ª K ç»´å‘é‡ï¼Œè¡¨ç¤º K ä¸ªä¸åŒç±»åˆ«æˆ–äº‹ä»¶çš„æ¦‚ç‡ã€‚ è¿™äº›æ¦‚ç‡ä¹‹å’Œå¿…é¡»ä¸º 1ï¼Œ
$\boldsymbol{\alpha} = (\alpha_1, \ldots, \alpha_K)$æ˜¯ä¸€ä¸ªæ­£å‚æ•°å‘é‡ï¼Œ$\alpha_i$ä»£è¡¨äº†ç¬¬$i$ä¸ªç±»åˆ«çš„å…ˆéªŒï¼Œæˆ–è€…è¯´è®¡æ•°ã€‚
$\beta(\alpha)$æ˜¯å¤šé¡¹å¼Betaå‡½æ•°ï¼Œä½œä¸ºå½’ä¸€åŒ–å¸¸æ•°ï¼Œä¿è¯æ€»æ¦‚ç‡ç§¯åˆ†ä¸º1ã€‚å®šä¹‰ä¸ºï¼š$B(\boldsymbol{\alpha}) = \frac{\prod_{i=1}^{K} \Gamma(\alpha_i)}{\Gamma\left(\sum_{i=1}^{K} \alpha_i\right)}$ï¼Œåœ¨è¿™ä¸ªå…¬å¼ä¸­$\Gamma$è¡¨ç¤ºGammaå‡½æ•°ï¼Œå®ƒæ˜¯é˜¶ä¹˜å‡½æ•°ï¼ˆå…¶å‚æ•°å‘ä¸‹ç§»åŠ¨ 1ï¼‰åˆ°å®æ•°å’Œå¤æ•°çš„æ‰©å±•ã€‚
Dirichletåˆ†å¸ƒæ˜¯ Beta åˆ†å¸ƒå‘æ›´é«˜ç»´åº¦çš„æ¨å¹¿ã€‚ åœ¨äºŒç»´æƒ…å†µä¸‹ï¼ˆK=2ï¼‰ï¼ŒDirichletåˆ†å¸ƒç®€åŒ–ä¸º Beta åˆ†å¸ƒã€‚
ä»€ä¹ˆæ˜¯Multinomial(å¤šé¡¹åˆ†å¸ƒ) å¤šé¡¹åˆ†å¸ƒæ˜¯äºŒé¡¹åˆ†å¸ƒå¯¹ä¸¤ä¸ªä»¥ä¸Šç±»åˆ«çš„æ¨å¹¿ã€‚ å®ƒæè¿°äº†æ»šåŠ¨ n æ¬¡ K é¢éª°å­æ¯ä¸€é¢å¯èƒ½è®¡æ•°çš„æ¦‚ç‡ã€‚ ç®€å•æ¥è¯´ï¼Œå®ƒæ˜¯å›ºå®šæ¬¡æ•°è¯•éªŒä¸­å¤šä¸ªç±»åˆ«è®¡æ•°çš„åˆ†å¸ƒã€‚
ç‰¹ç‚¹ï¼š
ç±»åˆ«ï¼šæœ‰ K ç§å¯èƒ½çš„ç»“æœæˆ–ç±»åˆ«ã€‚ è¯•éªŒï¼šæœ‰ n ä¸ªç‹¬ç«‹è¯•éªŒã€‚ æ¦‚ç‡ï¼šæ¯æ¬¡è¯•éªŒéƒ½æ°å¥½äº§ç”Ÿ K ä¸ªç±»åˆ«ä¸­çš„ä¸€ä¸ªã€‚ æ¯æ¬¡è¯•éªŒçš„æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡éƒ½æ˜¯å›ºå®šçš„ï¼Œå¹¶è¡¨ç¤ºä¸ºï¼š$p_1,p_2,\dots,p_k$ï¼Œå…¶ä¸­$âˆ‘p_i=1$ Probability Mass Function(PMF): ç»™å®šç»“æœ$x=(x_1,x_2,\dots,x_K)$çš„å¤šé¡¹åˆ†å¸ƒçš„pmfä¸ºï¼š $$P(X = x) = \frac{n!}{x_1! x_2! \ldots x_K!} p_1^{x_1} p_2^{x_2} \ldots p_K^{x_K} $$ å…¶ä¸­ï¼Œ$x_i$ä¸º$i$ç±»åˆ«çš„è®¡æ•°ï¼Œä¸” $\sum_{i=1}^{K} x_{i} = n$ã€‚
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-13 19:12:16 +0100 CET'>November 13, 2024</span>&nbsp;Â·&nbsp;3 min</footer>
  <a class="entry-link" aria-label="post link to DirichletMultinominal" href="https://oldhuntor.github.io/posts/dirichletmultinominal/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">PoissonGamma
    </h2>
  </header>
  <div class="entry-content">
    <p>@TOC ä¸Šä¸€ç¯‡æ–‡ç« æˆ‘ä»¬å°†äº†å¦‚ä½•åˆ©ç”¨beta- binomialå…±è½­åˆ†å¸ƒæ¥è®¾è®¡äº¤æ˜“ç­–ç•¥ã€‚é‚£æˆ‘ä»¬æ˜¯å¦å¯ä»¥ç”¨ä¼½é©¬å’ŒæŸæ¾ï¼ˆgamma- poissonï¼‰å…±è½­æ¥è®¾è®¡äº¤æ˜“ç­–ç•¥å‘¢ï¼Ÿæœ¬æ–‡å°†å±•ç¤ºä¸€ç§äº¤æ˜“ç­–ç•¥ä¾‹å­ã€‚
æ¨¡å‹ ç›®æ ‡ï¼šæ¨¡æ‹Ÿä¸€æ®µæ—¶é—´å†…çš„å¹³å‡ä¸Šæ¶¨æ¬¡æ•° å…ˆéªŒåˆ†å¸ƒï¼šgammaåˆ†å¸ƒï¼Œä»¥ä¸‹æ˜¯gammaåˆ†å¸ƒçš„åˆ†å¸ƒå‡½æ•°ï¼š $$ f(x; \alpha, \beta) = \frac{\beta^{\alpha} x^{\alpha - 1} e^{-\beta x}}{\Gamma(\alpha)} $$ ä»¥ä¸‹æ˜¯gammaåˆ†å¸ƒå‡½æ•°åœ¨ä¸åŒå‚æ•°ä¸‹çš„å›¾åƒï¼š å¯ä»¥çœ‹å‡ºï¼Œgammaåˆ†å¸ƒçš„å®šä¹‰åŸŸæ˜¯[0, &#43;$\infty$]ï¼Œè¿™è¯´æ˜ï¼Œæˆ‘ä»¬ä¸èƒ½å†é€‰æ‹©ç ”ç©¶ä¸Šæ¶¨æ¦‚ç‡$\theta$è¿™ç§0åˆ°1çš„å‚æ•°äº†ï¼Œæˆ‘ä»¬å¯ä»¥ç ”ç©¶ä¸€æ®µæ—¶é—´å†…å¹³å‡ä¸Šæ¶¨æ¬¡æ•°$\lambda$ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆéœ€è¦é€‰æ‹©æŸæ¾åˆ†å¸ƒæ¥è®¡ç®—likelihoodçš„åŸå› ã€‚
æŸæ¾åˆ†å¸ƒä¼¼ç„¶å‡½æ•°ï¼š æŸæ¾åˆ†å¸ƒåªæœ‰ä¸€ä¸ªå‚æ•°$\lambda$ï¼Œ æˆ‘ä»¬æŠŠå®ƒå®šä¹‰ä¸ºä¸€æ®µæ—¶é—´å†…çš„ä¸Šæ¶¨æ¬¡æ•°ã€‚ ä»¥ä¸‹æ˜¯æŸæ¾åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼š $$L(\lambda; k) = \frac{e^{-\lambda} \lambda^k}{k!}$$ ä»¥ä¸‹æ˜¯æŸæ¾åˆ†å¸ƒæ¦‚ç‡å¯†åº¦å›¾åƒï¼š å¯ä»¥çœ‹å‡ºæŸæ¾åˆ†å¸ƒæ˜¯ä¸€ä¸ªç¦»æ•£åˆ†å¸ƒï¼Œè¿™ç§ç¦»æ•£åˆ†å¸ƒæ­£å¥½å¯ä»¥ç”¨æ¥æ¨¡æ‹Ÿä¸Šæ¶¨æ¬¡æ•°è¿™ç§ç¦»æ•£å€¼ã€‚ å¦‚æœæˆ‘ä»¬å‡å®šæ¯ä¸€æ®µæ—¶é—´çš„ä¸Šæ¶¨æ¬¡æ•°æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨æŸæ¾çš„ä¼¼ç„¶å‡½æ•°ã€‚ ä»¥ä¸‹æ˜¯æŸæ¾åˆ†å¸ƒçš„ä¼¼ç„¶å‡½æ•°ï¼š $$L(\lambda; x_1, x_2, \ldots, x_n) = e^{-n\lambda} \lambda^{\sum_{i=1}^{n}x_i} \prod_{i=1}^{n} \frac{1}{x_i!} $$ åéªŒåˆ†å¸ƒ åœ¨æœ‰äº†å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶å‡½æ•°ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥è®¡ç®—åéªŒåˆ†å¸ƒäº†ï¼ŒåéªŒåˆ†å¸ƒå¦‚ä¸‹ï¼š $$p(\lambda | x_1, x_2, \ldots, x_n; \alpha&#39;, \beta&#39;) = \frac{{\beta&#39;}^{\alpha&#39;}}{\Gamma(\alpha&#39;)} \lambda^{\alpha&#39; - 1} e^{-\beta&#39; \lambda} $$ $$\alpha&#39; = \alpha &#43; \sum_{i=1}^{n} x_i,\beta&#39; = \beta &#43; n$$ å¯ä»¥å‘ç°ï¼ŒåéªŒåˆ†å¸ƒä¹Ÿæ˜¯gammaåˆ†å¸ƒï¼Œå¹¶ä¸”åéªŒåˆ†å¸ƒçš„$\alpha$ä¸$\beta$å¯ä»¥ç›´æ¥é€šè¿‡è§‚æµ‹æ ·æœ¬çš„ä¿¡æ¯å¾—åˆ°ï¼Œè¿™ä¸ªè®¡ç®—æä¾›äº†æå¤§ä¾¿åˆ©ã€‚ åº”ç”¨ä¾‹å­ é•¿å‘¨æœŸ é•¿å‘¨æœŸå†³å®šgammaåˆ†å¸ƒå…ˆéªŒã€‚ é•¿å‘¨æœŸçš„å•ä½ä¸ºå°æ—¶kã€‚ é•¿å‘¨æœŸçš„åºåˆ—æ˜¯ nå¤©çš„å°æ—¶kï¼Œç”± 7 * 24 * 60 = 10080 æ¡åˆ†é’Ÿkåˆæˆ ç„¶åè®¡ç®—24 å°æ—¶ä¸­ï¼Œ æ¯å¤©çš„ä¸Šæ¶¨æ¬¡æ•° ï¼Œ{â€œday1â€: 13, â€œday2â€: 6, â€œday3â€: 8â€¦.â€œdaynâ€: x} è®¡ç®—å‡ºæ ·æœ¬å¹³å‡æ•°å’Œæ–¹å·®æ¥ä¼°è®¡ ï¼ˆMoment method, çŸ©ä¼°è®¡ï¼‰ å…ˆéªŒçš„alpha prior å’Œ beta prior $\bar{x} = \frac{\alpha}{\beta}$,$s^2 = \frac{\alpha}{\beta^2}$
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-13 19:12:16 +0100 CET'>November 13, 2024</span>&nbsp;Â·&nbsp;4 min</footer>
  <a class="entry-link" aria-label="post link to PoissonGamma" href="https://oldhuntor.github.io/posts/poissongamma/"></a>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://oldhuntor.github.io/">Xuanhao&#39;s Blog</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
